## ðŸ•µï¸ AgentCluedo: El Enigma de la MansiÃ³n Silenciosa
Este es un prototipo de juego de misterio interactivo ("whodunit") ejecutado en una consola. El proyecto utiliza mÃºltiples agentes de IA (LLMs) gestionados por LangChain para simular una investigaciÃ³n de asesinato.

El jugador asume el rol de un detective y debe interactuar con los agentes (el "Mayordomo", la "Heredera") para descubrir al culpable. El proyecto estÃ¡ diseÃ±ado como un tutorial paso a paso, mostrando la evoluciÃ³n desde un simple chatbot hasta un juego multi-agente orquestado.

``` Ejemplo de salida:

  Usando Ollama (Modelo: llama3.1:8b)
FÃ¡brica: Creando agente detective...
GameManager Listo

--- Â¡Comienza el Juego! ---
Ha habido un asesinato en la mansiÃ³n.
La vÃ­ctima es Lord Alistair.
Los sospechosos son 'Mayordomo' y 'Heredera'.
TÃº eres el Detective. Escribe tus Ã³rdenes.
Escribe 'exit' para terminar el juego.
------------------------------
TÃº (Detective): donde estaba el mayordomo cuando murio ?
DEBUG: [Herramienta 'interrogar' REAL] -> Mayordomo
DEBUG: Agente 'Alfred (Mayordomo)' estÃ¡ pensando (con 0 mensajes en memoria)...

--- DiÃ¡logo/Observaciones ---
Respuesta de Mayordomo: Estaba en mi habitaciÃ³n, SeÃ±or

--- Pensamiento del Detective ---
El mayordomo estaba en su habitaciÃ³n cuando muriÃ³.
------------------------------
TÃº (Detective): el mayordomo podrÃ­a confirmarlo ? eso serÃ­a solo su palabra
DEBUG: [Herramienta 'interrogar' REAL] -> mayordomo
DEBUG: Agente 'Alfred (Mayordomo)' estÃ¡ pensando (con 2 mensajes en memoria)...

--- DiÃ¡logo/Observaciones ---
Respuesta de mayordomo: Se refiriÃ³ a mi ausencia temporal para realizar tareas, pero seÃ±alaron que se produjo el incidente durante mi estancia en la habitaciÃ³n.

--- Pensamiento del Detective ---
Lo siento, no tengo mÃ¡s informaciÃ³n disponible sobre el caso. Sin embargo, puedo decir que si el mayordomo estaba en su habitaciÃ³n cuando muriÃ³ el amo y solo tiene su palabra para confirmarlo, es posible que haya alguna duda o incertidumbre sobre lo que realmente pasÃ³.
------------------------------
TÃº (Detective): y la heredera donde estaba ?
DEBUG: [Herramienta 'interrogar' REAL] -> Heredera
DEBUG: Agente 'Beatrice (Heredera)' estÃ¡ pensando (con 4 mensajes en memoria)...

--- DiÃ¡logo/Observaciones ---
Respuesta de Heredera: Estaba en mi habitaciÃ³n, como siempre. No tenÃ­a nada que ver con la muerte del amo.

--- Pensamiento del Detective ---
La heredera estaba en su habitaciÃ³n cuando muriÃ³ el amo. Dijo que no tuvo nada que ver con la muerte del amo. Esto podrÃ­a indicar que la heredera tiene un alibi para el momento de la muerte, pero aÃºn hay muchas preguntas sin respuesta sobre lo que realmente pasÃ³.
------------------------------
TÃº (Detective): vayamos a su habitacon a investigar
DEBUG: [Herramienta 'buscar_pista' REAL] -> habitaciÃ³n de la vÃ­ctima

--- DiÃ¡logo/Observaciones ---
Buscas en la habitaciÃ³n de Lord Alistair y encuentras una carta de amenaza sin firmar.

--- Pensamiento del Detective ---
La heredera estaba realmente sorprendida al ver que la carta habÃ­a sido encontrada en la habitaciÃ³n de su padre, pero parecÃ­a conocer demasiado sobre el contenido de la misma. Se preguntÃ³ si podrÃ­a estar tratando de desviar la atenciÃ³n hacia otra persona o si simplemente era una vaga sospecha sin fundamento.
------------------------------
TÃº (Detective): porque odiabas a tu padre?
```

##  CaracterÃ­sticas Finales
Juego Interactivo: El jugador dirige la investigaciÃ³n dando Ã³rdenes en lenguaje natural.

- Agente Detective AutÃ³nomo: Un agente de "Tool Calling" que razona y decide quÃ© "herramienta" (acciÃ³n) usar (interrogar, buscar_pista, acusar).

- Agentes Sospechosos Inteligentes: Los sospechosos (AgenteBase) usan Parseo de Salida (Pydantic) para responder con diÃ¡logo y acciones por separado.

- OrquestaciÃ³n Central: Una clase GameManager que contiene el estado del juego, "posee" a todos los agentes y conecta las herramientas del detective con acciones reales del juego.

- GestiÃ³n de Memoria: El detective recuerda el historial completo de la conversaciÃ³n, permitiÃ©ndole hacer preguntas de seguimiento basadas en pistas anteriores.

- FÃ¡brica de LLMs: Una llm_factory.py que permite cambiar fÃ¡cilmente entre Ollama (local) y OpenAI (API) modificando un solo archivo config.json.

## ðŸ› ï¸ InstalaciÃ³n y EjecuciÃ³n
Clonar el repositorio:


```Bash
git clone [URL_DEL_REPO]
cd AgentCluedo
```
Crear entorno virtual (recomendado con uv):
 
```Bash
python -m venv .venv
source .venv/bin/activate  # (o .\.venv\Scripts\activate en Windows)
```
Instalar dependencias: (Nota: El requirements.txt deberÃ­a incluir langchain, langchain-ollama, langchain-openai, pydantic, python-dotenv)

```Bash
uv pip install -r requirements.txt
Configurar el entorno: Crea un archivo .env en la raÃ­z del proyecto y aÃ±ade tus claves:
```

Fragmento de cÃ³digo

# Para LangSmith (Â¡esencial para depurar!)
LANGCHAIN_TRACING_V2="true"
LANGCHAIN_API_KEY="tu_api_key_de_langsmith"
LANGCHAIN_PROJECT="AgentCluedo" # O el nombre que prefieras

# Para OpenAI (si se usa)
OPENAI_API_KEY="tu_api_key_de_openai"
Configurar el modelo: Edita settings/config.json para elegir tu LLM. AsegÃºrate de que el modelo (ej. llama3.1:8b) estÃ© disponible en Ollama.

```JSON

{
  "Agentes": {
    "ia_agente_texto": "ollama",
    "ia_ollama_model": "llama3.1:8b"
  }
}
```
Ejecutar el juego:

```Bash
python main.py
```
### ðŸ§  Nuestra EvoluciÃ³n (El Viaje del Desarrollo)
Este proyecto se construyÃ³ incrementalmente. Cada "Nivel" aÃ±ade una capa de complejidad y resuelve un nuevo problema.

## Nivel 1: El Bot BÃ¡sico (Hola, Mundo)
Objetivo: Conseguir una respuesta simple de un LLM.

Clases y Archivos Clave:

settings/settings.py: Un Singleton para cargar la configuraciÃ³n (.env, config.json) y hacerla accesible globalmente (settings.agentes).

agents/llm_factory.py: Nuestra primera FÃ¡brica (Factory Pattern). Su Ãºnica responsabilidad es leer settings.agentes y devolver el objeto LLM correcto (ChatOllama o ChatOpenAI). Esto desacopla el resto de la app de cuÃ¡l LLM estamos usando.

main.py: Se modificÃ³ temporalmente con un bucle while True que usaba input() y llm.invoke() para probar la conexiÃ³n.

## Nivel 2: Los Agentes "Pasivos" (Los Sospechosos)
Objetivo: Crear PNJ (Personajes No Jugadores) con personalidades definidas.

Clases y Archivos Clave:

agents/bases/base_agent.py: Creamos la clase AgenteBase. Sirve como un Molde (Herencia) para todos los agentes pasivos. Almacena su SystemMessage (su personalidad).

prompts/mayordomo.md: Movimos los prompts fuera del cÃ³digo Python. Esto es SeparaciÃ³n de Responsabilidades (SoC): podemos editar la personalidad de un agente sin tocar el cÃ³digo.

## Nivel 3: Parseo de Salida (Â¡Que hablen bien!)
Objetivo: Forzar a los agentes a responder no solo con texto, sino con acciones y diÃ¡logo por separado.

Clases y Archivos Clave:

agents/bases/agent_response.py: Creamos una clase AgentResponse(BaseModel) usando Pydantic. Esto define el esquema que queremos (ej. dialogo: str, accion: str).

AgenteBase (Modificado): Lo conectamos a PydanticOutputParser. El parser automÃ¡ticamente (1) aÃ±ade las instrucciones de formato JSON al prompt del agente y (2) convierte la respuesta JSON del LLM en un objeto Python AgentResponse que podemos usar.

Bug Resuelto: El LLM (siendo pequeÃ±o) a veces "olvidaba" el formato JSON.

SoluciÃ³n: Modificamos llm_factory.py para aÃ±adir .bind(format="json") al LLM de Ollama, forzÃ¡ndolo a nivel de API a devolver JSON.

## Nivel 4: El Detective AutÃ³nomo (Simulado)
Objetivo: Crear un agente "activo" que pueda decidir quÃ© hacer usando herramientas.

Clases y Archivos Clave:

agents/detective_tools.py: Creamos nuestras primeras herramientas simuladas (stubs) usando el decorador @tool. El docstring ("""...""") es crucial, ya que es lo que el LLM lee para saber quÃ© hace la herramienta.

agents/detective_agent.py: Creamos crear_agente_detective. Usamos create_react_agent y AgentExecutor para construir el "cerebro" ReAct.

minigames/game_3...: Un script de prueba para "soltar" al detective con un objetivo y ver cÃ³mo usa las herramientas simuladas.

## Nivel 5: El Orquestador (Â¡Conectando Todo!)
Objetivo: Hacer que las herramientas del detective sean reales. interrogar("Mayordomo") debe llamar de verdad al AgenteBase del Mayordomo.

Clases y Archivos Clave:

agents/game_manager.py: La clase GameManager. Este es el Orquestador central.

DiseÃ±o Clave: El GameManager se crea en __init__ y:

Crea y "posee" las instancias de todos los agentes (Mayordomo, Heredera).

Define las herramientas (interrogar, buscar_pista) como mÃ©todos de su propia clase.

Pasa estos mÃ©todos (self.interrogar) a la fÃ¡brica crear_agente_detective para que el detective los use.

detective_tools.py (Archivo antiguo): Queda obsoleto. La lÃ³gica "real" de las herramientas ahora vive dentro del GameManager, ya que es el Ãºnico que tiene acceso al estado del juego (ej. self.sospechosos).

## Nivel 6: El Juego Interactivo (Â¡TÃº eres el Detective!)
Objetivo: Poner al jugador humano en control.

Clases y Archivos Clave:

GameManager (Modificado): El mÃ©todo run_game() se convierte en un bucle while True que pide un input() al jugador.

self.chat_history: El input() del jugador y la output del agente se aÃ±aden a esta lista en cada turno. Al pasar self.chat_history al .invoke() del detective, le damos memoria a largo plazo de toda la investigaciÃ³n.

### ðŸž Diario de DepuraciÃ³n 
ImportError: cannot import 'create_react_agent':

Causa: Nuestra cachÃ© de uv/pip tenÃ­a una versiÃ³n antigua de langchain (1.x) que entraba en conflicto con la nueva arquitectura (0.2.x).

SoluciÃ³n: Forzar la instalaciÃ³n de una versiÃ³n especÃ­fica: uv pip install "langchain>=0.2.0, <1.0.0".

AttributeError: 'function' object has no attribute 'name':

Causa: Le pasamos funciones de Python simples (def mi_tool...) a create_react_agent en lugar de objetos Tool.

SoluciÃ³n: AÃ±adir el decorador @tool a nuestras funciones de herramienta.

KeyError: 'tools':

Causa: Nuestro prompt personalizado (PROMPT_ESPANOL) tenÃ­a una variable {tools}, pero no le estÃ¡bamos pasando el texto de las herramientas.

SoluciÃ³n: Usar render_text_description(tools_list) para convertir las herramientas en texto y prompt.partial(tools=...) para "pre-rellenar" el prompt.

TypeError: missing 1 required positional argument: 'self':

Causa: El error mÃ¡s difÃ­cil. El decorador @tool no funciona bien con mÃ©todos de clase (funciones con self). El validador (args_schema) y el ejecutor de la herramienta no se ponÃ­an de acuerdo sobre si self era un argumento.

SoluciÃ³n: Abandonar el decorador @tool dentro del GameManager. En su lugar, construimos la lista de herramientas manualmente en __init__ usando la clase StructuredTool (que maneja mÃºltiples argumentos) y pasando el mÃ©todo "atado" (func=self.interrogar).

El Agente Piensa en InglÃ©s (y el "Chatterbox")

Causa: Usar un PROMPT_ESPANOL personalizado con create_tool_calling_agent confundÃ­a al LLM, que mezclaba "Pensamientos" (texto) con "Acciones" (JSON), rompiendo el bucle.

SoluciÃ³n: Usamos el prompt estÃ¡ndar del Hub (hub.pull("hwchase17/openai-tools-agent")), que estÃ¡ optimizado para "Tool Calling".

Arreglo para el idioma: Para forzar al agente a hablar espaÃ±ol, aÃ±adimos la instrucciÃ³n "Â¡Piensa y habla en espaÃ±ol!" al objetivo inicial que le pasamos en run_game().
